<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Huazheng Wang</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-129163640-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Huazheng Wang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="index.html" class="current">Publication</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="https://github.com/huazhengwang/">GitHub</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=w3PrbKwAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Huazheng Wang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/bio1.jpg" alt="alt qtext" width="160px" height="190px" />&nbsp;</td>
<td align="left"><p>Assistant Professor,<br />
School of Electrical Engineering and Computer Science, <br />
Oregon State University<br />
Email: huazheng.wang [at] oregonstate.edu</p>
</td></tr></table>
<h2>About me</h2>
<p>I am an Assistant Professor in the School of Electrical Engineering and Computer Science (EECS) at Oregon State University. I was a Postdoctoral Research Associate at the Department of Electrical and Computer Engineering at Princeton University from 2021 to 2022, hosted by <a href="https://mwang.princeton.edu/">Dr. Mengdi Wang</a>. I received my Ph.D. in Computer Science at University of Virginia in 2021, supervised by <a href="http://www.cs.virginia.edu/~hw5x/">Dr. Hongning Wang</a>. I received my B.Eng. in Computer Science at University of Science and Technology of China in 2015. 
My research interests include reinforcement learning, information retrieval and machine learning in general. I recently focused on developing provably efficient and trustworthy reinforcement learning and multi-armed bandit algorithms with applications to information retrieval tasks such as recommendation, ranking, and LLMs, and scientific discovery problems in biology and chemistry. </p>
<p><font color=red> I am looking for self-motivated PhD students with solid math and coding backgrounds starting Fall 2025. More information can be found here for <a href="prospective_students.html">prospective students</a>.</font></p>
<h3>News and Updates</h3>
<ul>
<li><p>[09/2024] One paper on risk-aware preference-based RL is accepted by NeurIPS 2024.</p>
</li>
<li><p>[08/2024] We received a new NSF award (<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2403401">IIS-2403401</a>) on Neural Bandits. Thank you NSF!</p>
</li>
<li><p>[05/2024] One <a href="https://arxiv.org/abs/2407.18488">paper</a> on conversational dueling bandits is accepted by KDD 2024.</p>
</li>
<li><p>[05/2024] One <a href="https://arxiv.org/abs/2310.05308">paper</a> on adversarial attack on combinatorial bandits is accepted by ICML 2024.</p>
</li>
<li><p>[04/2024] One <a href="https://arxiv.org/abs/2310.11015">paper</a> on fedrated pure exploration is accepted by UAI 2024.</p>
</li>
<li><p>[01/2024] One <a href="https://arxiv.org/abs/2308.02585">paper</a> on policy alignment is accepted by ICLR 2024.</p>
</li>
<li><p>[12/2023] Two papers accepted by AAAI 2024: one on <a href="https://arxiv.org/abs/2401.06173">tree search bandits for protein optimization</a> and one on stealthy attack against MAB.</p>
</li>
<li><p>[09/2023] One paper on offline RL for learning to rank is accepted by NeurIPS 2023.</p>
</li>
<li><p>[04/2023] One paper on representation learning in POMDP is accepted by ICML 2023. See you in Hawaii.</p>
</li>
<li><p>[01/2023] Our <a href="https://openreview.net/forum?id=-G1kjTFsSsdistributed">asynchronous kernel bandits</a> paper is accepted by ICLR 2023.</p>
</li>
<li><p>[09/2022] Two papers accepted by NeurIPS 2022: one on <a href="https://arxiv.org/abs/2206.04835">distributed kernel bandits</a> and the other on <a href="https://arxiv.org/abs/2206.02092">Thompson Sampling for Directed Evolution</a>. </p>
</li>
<li><p>[09/2022] Joined EECS at Oregon State University as an Assistant Professor.</p>
</li>
</ul>
<h3>Honors and Awards</h3>
<ul>
<li><p>[08/2019], <a href="http://sigir.org/awards/best-paper-awards/">SIGIR 2019 Best Paper Award</a>.</p>
</li>
<li><p>[2018 - 2021], Bloomberg Data Science Ph.D. Fellowship.</p>
</li>
<li><p>[08/2021], ICML 2021 Best Reviewers (Top 10%).

</p>
</li>
</ul>
<h3>Publications </h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2410.23569">RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement Learning</a><br />
Yujie Zhao, Jose Aguilar Escamilla, Weyl Lu, Huazheng Wang. NeurIPS 2024. <a href="https://arxiv.org/abs/2410.23569">[arXiv]</a> <a href="https://github.com/aguilarjose11/PbRLNeurips">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2305.19218">Adversarial Attacks on Online Learning to Rank with Stochastic Click Models</a><br />
Zichen Wang, Rishab Balasubramanian, Hui Yuan, Chenyu Song, Mengdi Wang, Huazheng Wang. Transactions on Machine Learning Research (TMLR), 2024. <a href="https://arxiv.org/abs/2305.19218">[arXiv]</a> <a href="https://github.com/rishabbala/Online-Learning-to-Rank-for-Stochastic-Click-Models">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2407.18488">Conversational Dueling Bandits in Generalized Linear Models</a><br />
Shuhua Yang, Hui Yuan, Xiaoying Zhang, Mengdi Wang, Hong Zhang, Huazheng Wang. KDD 2024. <a href="https://arxiv.org/abs/2407.18488">[arXiv]</a> <a href="https://github.com/shuashua0608/Con-Duel">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2310.05308">Adversarial Attacks on Combinatorial Multi-Armed Bandits</a><br />
Rishab Balasubramanian, Jiawei Li, Prasad Tadepalli, Huazheng Wang, Qingyun Wu, Haoyu Zhao (Alphabetic order). ICML 2024. <a href="https://arxiv.org/abs/2310.05308">[arXiv]</a> <a href="https://github.com/rishabbala/robust-cmab-code">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2310.11015">Pure Exploration in Asynchronous Federated Bandits</a><br />
Zichen Wang, Chuanhao Li, Chenyu Song, Lianghui Wang, Quanquan Gu, Huazheng Wang. UAI 2024. <a href="https://arxiv.org/abs/2310.11015">[arXiv]</a> <a href="https://github.com/Lianghui818/Pure_Exploration">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2308.02585">PARL: A Unified Framework for Policy Alignment in Reinforcement Learning</a><br />
Souradip Chakraborty, Amrit Singh Bedi, Alec Koppel, Dinesh Manocha, Huazheng Wang, Furong Huang, Mengdi Wang. ICLR 2024. <a href="https://arxiv.org/abs/2308.02585">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2401.06173">Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization</a><br />
Jiahao Qiu, Hui Yuan, Jinghong Zhang, Wentao Chen, Huazheng Wang, Mengdi Wang. AAAI 2024. <a href="https://arxiv.org/abs/2401.06173">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2402.13487">Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits</a><br />
Zhiwei Wang, Huazheng Wang, Hongning Wang. AAAI 2024. <a href="https://arxiv.org/abs/2402.13487">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2306.07528">Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective</a><br />
Zeyu Zhang, Yi Su, Hui Yuan, Yiran Wu, Rishab Balasubramanian, Qingyun Wu, Huazheng Wang, Mengdi Wang. NeurIPS 2023. <a href="https://arxiv.org/abs/2306.07528">[arXiv]</a> <a href="https://github.com/ZeyuZhang1901/Unified-Off-Policy-LTR-Neurips2023">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2306.12356">Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP</a><br />
Jiacheng Guo, Zihao Li, Huazheng Wang, Mengdi Wang, Zhuoran Yang, Xuezhou Zhang. International Conference on Machine Learning (ICML 2023). <a href="https://arxiv.org/abs/2306.12356">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2104.03860">Incentivizing Exploration in Linear Bandits under Information Gap</a><br />
Huazheng Wang, Haifeng Xu, Chuanhao Li, Zhiyuan Liu, Hongning Wang. Proceedings of the 17th ACM Conference on Recommender Systems (RecSys 2023). <a href="https://arxiv.org/abs/2104.03860">[arXiv]</a></p>
</li>
<li><p><a href="https://openreview.net/forum?id=-G1kjTFsSs">Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment</a><br />
Chuanhao Li, Huazheng Wang, Mengdi Wang, Hongning Wang.  The Eleventh International Conference on Learning Representations (ICLR 2023). <a href="https://openreview.net/forum?id=-G1kjTFsSs">[paper]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.02092">Bandit Theory and Thompson Sampling-Guided Directed Evolution for Sequence Optimization</a><br />
Hui Yuan, Chengzhuo Ni, Huazheng Wang, Xuezhou Zhang, Le Cong, Csaba Szepesv√°ri, Mengdi Wang. Advances in Neural Information Processing Systems 35 (NeurIPS 2022). <a href="https://arxiv.org/abs/2206.02092">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.04835">Communication Efficient Distributed Learning for Kernelized Contextual Bandits</a><br />
Chuanhao Li, Huazheng Wang, Mengdi Wang, Hongning Wang. Advances in Neural Information Processing Systems 35 (NeurIPS 2022). <a href="https://arxiv.org/abs/2206.04835">[arXiv]</a> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2208.14555">Dynamic Global Sensitivity for Differentially Private Contextual Bandits</a><br />
Huazheng Wang, David Zhao, Hongning Wang. Proceedings of the 16th ACM Conference on Recommender Systems (RecSys 2022). <a href="https://arxiv.org/abs/2208.14555">[arXiv]</a> </p>
</li>
<li><p><a href="https://proceedings.mlr.press/v162/wang22ai.html">When Are Linear Stochastic Bandits Attackable?</a><br />
Huazheng Wang, Haifeng Xu, Hongning Wang. International Conference on Machine Learning (ICML 2022). <a href="https://arxiv.org/abs/2110.09008">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2103.00368">PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer</a><br />
Yiling Jia, Huazheng Wang, Stephen Guo, Hongning Wang, Proceedings of the Web Conference 2021 (WWW 2021).  <font color=red>Nominated for the Best Paper Award</font> <a href="https://arxiv.org/abs/2103.00368">[arXiv]</a> <a href="https://github.com/yilingjia/PairRank">[code]</a></p>
</li>
<li><p><a href="papers/RecSys2020_DPCoLin_Wang.pdf">Global and Local Differential Privacy for Collaborative Bandits</a><br />
Huazheng Wang, Qian Zhao, Qingyun Wu, Shubham Chopra, Abhinav Khaitan, Hongning Wang, Fourteenth ACM Conference on Recommender Systems (RecSys 2020). <a href="papers/RecSys2020_DPCoLin_Wang.pdf">[pdf]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.13574">Unbiased Learning to Rank: Online or Offline?</a><br />
Qingyao Ai, Tao Yang, Huazheng Wang, Jiaxin Mao, ACM Transactions on Information Systems (TOIS). <a href="https://arxiv.org/abs/2004.13574">[arXiv]</a> <a href="https://github.com/ULTR-Community/ULTRA">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2007.08561">A Smoothed Analysis of Online Lasso for the Sparse Linear Contextual Bandits Problem</a><br /> 
Zhiyuan Liu, Huazheng Wang, Bo Waggoner, Youjian(Eugene) Liu, Lijun Chen, Workshop on Real World Experiment Design and Active Learning at ICML 2020. <a href="https://arxiv.org/abs/2007.08561">[arXiv]</a></p>
</li>
<li><p><a href="papers/AAAI2020_RewardDrift_Liu.pdf">Incentivized Exploration for Multi-Armed Bandits under Reward Drift</a><br />
Zhiyuan Liu*, Huazheng Wang*, Fan Shen, Kai Liu and Lijun Chen, The 34th AAAI Conference on Artifical Intelligence (AAAI 2020). <a href="https://arxiv.org/abs/1911.05142">[arXiv]</a></p>
</li>
<li><p><a href="papers/EMNLP2019_AdaMRC_Wang.pdf">Adversarial Domain Adaptation for Machine Reading Comprehension</a><br /> Huazheng Wang, Zhe Gan, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Hongning Wang, (EMNLP 2019). <a href="https://arxiv.org/abs/1908.09209">[arXiv]</a></p>
</li>
<li><p><a href="papers/SIGIR2019-DocumentSpace-Wang.pdf">Variance Reduction in Gradient Exploration for Online Learning to Rank</a><br />
Huazheng Wang, Sonwoo Kim, Eric McCord-Snook, Qingyun Wu, Hongning Wang, The 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019). <font color=red>Best Paper Award</font> <a href="https://arxiv.org/abs/1906.03766">[arXiv]</a> <a href="https://github.com/sak2km/OnlineLearningToRank">[code]</a></p>
</li>
<li><p><a href="papers/KDD2019_MatrixFactorizationIM_Wu.pdf">Factorization Bandits for Online Influence Maximization</a><br />
Qingyun Wu, Zhige Li, Huazheng Wang, Wei Chen, Hongning Wang, The 25th ACM SIGKDD Conference On Knowledge Discovery And Data Mining (KDD 2019). <a href="https://arxiv.org/abs/1906.03737">[arXiv]</a> <a href="https://github.com/Matrix-Factorization-Bandit/IMFB-KDD2019">[code]</a></p>
</li>
<li><p><a href="papers/WWW2019-DenBandit-Wu.pdf">Dynamic Ensemble of Contextual Bandits to Satisfy Users&rsquo; Changing Interests</a><br />
Qingyun Wu, Huazheng Wang, Yanen Li, Hongning Wang, The Web Conference 2019 (WWW 2019). <a href="papers/WWW2019-DenBandit-Wu.pdf">[pdf]</a>  <a href="https://github.com/qingyun-wu/NonstationaryBanditLib">[code]</a></p>
</li>
<li><p><a href="papers/SIGIR18_NSGD_Wang.pdf">Efficient Exploration of Gradient Space for Online Learning to Rank</a><br />
Huazheng Wang, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, Hongning Wang, The 41th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2018). <a href="https://arxiv.org/pdf/1805.07317.pdf">[arXiv]</a> <a href="https://github.com/sak2km/OnlineLearningToRank">[code]</a></p>
</li>
<li><p><a href="papers/AAAI17_FactorUCB_Wang.pdf">Factorization Bandits for Interactive Recommendation</a><br />
Huazheng Wang, Qingyun Wu, Hongning Wang,  The 31st AAAI Conference on Artifical Intelligence (AAAI 2017). <a href="papers/AAAI17_FactorUCB_Wang.pdf">[pdf]</a> <a href="papers/AAAI17_FactorUCB_Wang_Supp.pdf">[Supplementary]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a></p>
</li>
<li><p><a href="papers/CIKM16_hLinUCB_Wang.pdf">Learning Hidden Features for Contextual Bandits</a><br />
Huazheng Wang, Qingyun Wu, Hongning Wang, The 25th ACM International Conference on Information and Knowledge Management (CIKM 2016). <a href="papers/CIKM16_hLinUCB_Wang.pdf">[pdf]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a></p>
</li>
<li><p><a href="papers/SIGIR16_CoLin_Wu.pdf">Contextual Bandits in A Collaborative Environment</a><br />
Qingyun Wu, Huazheng Wang, Quanquan Gu, Hongning Wang, The 39th  International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2016). <a href="papers/SIGIR16_CoLin_Wu.pdf">[pdf]</a> <a href="https://github.com/huazhengwang/banditlib">[code]</a></p>
</li>
<li><p><a href="papers/EMNLP16_iq_test_Wang.pdf">Solving Verbal Comprehension Problems in IQ Test by Knowledge-Powered Word Embedding</a><br />
Huazheng Wang, Fei Tian, Bin Gao, Chengjieren Zhu, Jiang Bian, Tie-Yan Liu, Conference on Empirical Methods in Natural Language Processing, 2016 (EMNLP-16). <a href="https://arxiv.org/abs/1505.07909">[arXiv]</a> <a href="https://www.dropbox.com/s/o0very1gwv3mrt5/VerbalQuestions.zip?dl=0">[data]</a></p>
</li>
</ul>
<h3>Preprints</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2410.13828">A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement</a><br />
Hui Yuan, Yifan Zeng, Yue Wu, Huazheng Wang, Mengdi Wang, Liu Leqi. <a href="https://arxiv.org/abs/2410.13828">[arXiv]</a> <a href="https://github.com/HumainLab/Understand_MarginPO">[code]</a> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2410.16033">TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling</a><br />
Jiahao Qiu, Yifu Lu, Yifan Zeng, Jiacheng Guo, Jiayi Geng, Huazheng Wang, Kaixuan Huang, Yue Wu, Mengdi Wang. <a href="https://arxiv.org/abs/2410.16033">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2406.00231">LLM-RankFusion: Mitigating Intrinsic Inconsistency in LLM-based Ranking</a><br /> 
Yifan Zeng, Ojas Tendolkar, Raymond Baartmans, Qingyun Wu, Lizhong Chen, Huazheng Wang. <a href="https://arxiv.org/abs/2406.00231">[arXiv]</a> <a href="https://github.com/XHMY/LLM-RankFusion">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2403.04783">AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks</a><br />  
Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu. <a href="https://arxiv.org/abs/2403.04783">[arXiv]</a> <a href="https://github.com/XHMY/AutoDefense">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2403.12482">Embodied LLM Agents Learn to Cooperate in Organized Teams</a><br /> 
Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia V√©lez, Qingyun Wu, Huazheng Wang, Thomas L. Griffiths, Mengdi Wang. <a href="https://arxiv.org/abs/2403.12482">[arXiv]</a> <a href="https://github.com/tobeatraceur/Organized-LLM-Agents">[code]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2405.20504">FCOM: A Federated Collaborative Online Monitoring Framework via Representation Learning</a><br /> 
Tanapol Kosolwattana, Huazheng Wang, Raed Al Kontar, Ying Lin. <a href="https://arxiv.org/abs/2405.20504">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2312.14291">Multi-Agent Join</a><br />
Vahid Ghadakchi, Mian Xie, Arash Termehchy, Bakhtiyar Doskenov, Bharghav Srikhakollu, Summit Haque, Huazheng Wang. <a href="https://arxiv.org/abs/2312.14291">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2307.14208">Online Modeling and Monitoring of Dependent Processes under Resource Constraints</a><br />
Tanapol Kosolwattana, Huazheng Wang, Ying Lin. <a href="https://arxiv.org/abs/2307.14208">[arXiv]</a> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2307.12975">Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems</a><br />
Xiang Ji, Huazheng Wang, Minshuo Chen, Tuo Zhao, Mengdi Wang. <a href="https://arxiv.org/abs/2307.12975">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2302.04062">Machine Learning for Synthetic Data Generation: A Review</a>
Yingzhou Lu, Minjie Shen, Huazheng Wang, Xiao Wang, Capucine van Rechem, Tianfan Fu, Wenqi Wei. <a href="https://arxiv.org/abs/2302.04062">[arXiv]</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2206.14846">Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization</a><br />
Kaixuan Huang, Yu Wu, Xuezhou Zhang, Shenyinying Tu, Qingyun Wu, Mengdi Wang, Huazheng Wang. <a href="https://arxiv.org/abs/2206.14846">[arXiv]</a></p>
</li>
</ul>
<h3>Tutorials</h3>
<ul>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">Interactive Information Retrieval with Bandit Feedback</a><br /> Huazheng Wang, Yiling Jia, Hongning Wang,
SIGIR 2021. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/sigir2021-iir-bandit/_site/files/Bandit4IR_full.pdf">[Slides]</a></p>
</li>
<li><p><a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">Learning by Exploration: New Challenges in Real-World Environments</a><br /> Qingyun Wu, Huazheng Wang, Hongning Wang,
KDD 2020. <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/">[Website]</a>  <a href="http://www.cs.virginia.edu/~hw5x/HCDM/tutorials/kdd2020-learning-by-exploration/_site/files/Learning%20by%20Exploration.pptx">[Slides]</a></p>
</li>
</ul>
<h3>Service</h3>
<ul>
<li><p>Area Chair: ICLR 2023, 2024; NeurIPS 2023; KDD 2024</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
